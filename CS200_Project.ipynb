{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS200 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waynel65/deep-learning-project/blob/main/CS200_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2LDrmGbisZ"
      },
      "source": [
        "**List of food that can be recongized**\n",
        "\n",
        "*   apple pie\n",
        "*   beignets\n",
        "*   bruschetta\n",
        "*   chicken wings\n",
        "*   chocolate cakes\n",
        "*   egg benedict\n",
        "*   fried calamari\n",
        "*   fried rice\n",
        "*   greek salad\n",
        "*   guacamole\n",
        "*   hamburger\n",
        "*   miso soup\n",
        "*   pizza\n",
        "*   pork chop\n",
        "*   prime rib\n",
        "*   ramen\n",
        "*   risotto\n",
        "*   sashimi\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjm-IPWBwKnW"
      },
      "source": [
        "## mounting google drive on google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOmssl-z_xJ"
      },
      "source": [
        "## check if the drive is mounted correctly\n",
        "PATH_OF_DATA = '/content/drive/\"My Drive\"/foodImages'\n",
        "!ls {PATH_OF_DATA}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUXLf3zeKeAP"
      },
      "source": [
        "## all the imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvINHyFGOGjk"
      },
      "source": [
        "## hyperparameters\n",
        "BATCH_SIZE = 100\n",
        "LEARNING_RATE = 0.005\n",
        "NUM_EPOCHs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-goSnbiJMEub"
      },
      "source": [
        "## data loading\n",
        "## challenge 1: could not divide the image data into training and testing set\n",
        "## challenge 2: each category has different number of samples\n",
        "\n",
        "img_transform = transforms.Compose([transforms.Resize((384, 384)), \n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406] , [0.229, 0.224, 0.225])]\n",
        ")\n",
        "\n",
        "img_dataset = datasets.ImageFolder(root = \"/content/drive/My Drive/foodImages\",\n",
        "                                   transform=img_transform)\n",
        "img_dataloader = torch.utils.data.DataLoader(img_dataset, batch_size = BATCH_SIZE,\n",
        "                                              shuffle = True, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zSJB54sOGyX"
      },
      "source": [
        "## pretrained model\n",
        "googlenet = models.googlenet(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCiGbRdSYGn"
      },
      "source": [
        "## neural network class\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.googlenet = googlenet\n",
        "\n",
        "    for p in self.googlenet.parameters():\n",
        "      p.require_grad = False  \n",
        "    \n",
        "    self.googlenet.fc = nn.Linear(1024, 18)\n",
        "    self.googlenet.fc.requires_grad = True\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.googlenet(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0PQ9_4V0e0"
      },
      "source": [
        "network = Network().cuda()  ## network instance\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "def num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nFBOzcaeyqb"
      },
      "source": [
        "for epoch in range(NUM_EPOCHs):\n",
        "  total_correct = 0.0\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for data in tqdm(img_dataloader, total=len(img_dataloader)):\n",
        "    images, labels = data\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    preds = network(images) ## prediction tensors\n",
        "    loss = loss_fn (preds, labels) ## calculate loss\n",
        "    loss.backward()\n",
        "    optimizer.step() ## update the weights (learning rate tells how far to step in the direction of local minimum)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_correct += num_correct(preds, labels)\n",
        "\n",
        "  print(\"Epoch: \", epoch, \"total correct: \", total_correct, \"total loss: \", total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMSoGHoZivtI"
      },
      "source": [
        "print(total_correct/len(img_dataset))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}